{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40118186",
   "metadata": {},
   "source": [
    "# Pyspark ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9523e54",
   "metadata": {},
   "source": [
    "## Processamento inicial dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8146d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "from pyspark.sql.functions import to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d167429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar variáveis para acessar HDFS (caso necessário)\n",
    "os.environ[\"HADOOP_USER_NAME\"] = \"root\"  # executa operações no HDFS como usuário root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9295355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar sessão Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SiasusETL\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f60938ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o arquivo CSV do HDFS\n",
    "# vamos definir esquemas manualmente em alguns casos\n",
    "# encoding Latin-1 para caracteres especiais\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", False) \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"encoding\", \"ISO-8859-1\") \\\n",
    "    .load(\"hdfs://localhost:9000/user/root/siasus/PSRS2301.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56086892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CNES_EXEC: string (nullable = true)\n",
      " |-- GESTAO: string (nullable = true)\n",
      " |-- CONDIC: string (nullable = true)\n",
      " |-- UFMUN: string (nullable = true)\n",
      " |-- TPUPS: string (nullable = true)\n",
      " |-- TIPPRE  : string (nullable = true)\n",
      " |-- MN_IND: string (nullable = true)\n",
      " |-- CNPJCPF: string (nullable = true)\n",
      " |-- CNPJMNT: string (nullable = true)\n",
      " |-- DT_PROCESS: string (nullable = true)\n",
      " |-- DT_ATEND: string (nullable = true)\n",
      " |-- CNS_PAC: string (nullable = true)\n",
      " |-- DTNASC: string (nullable = true)\n",
      " |-- TPIDADEPAC: string (nullable = true)\n",
      " |-- IDADEPAC: string (nullable = true)\n",
      " |-- NACION_PAC: string (nullable = true)\n",
      " |-- SEXOPAC: string (nullable = true)\n",
      " |-- RACACOR: string (nullable = true)\n",
      " |-- ETNIA: string (nullable = true)\n",
      " |-- MUNPAC: string (nullable = true)\n",
      " |-- MOT_COB: string (nullable = true)\n",
      " |-- DT_MOTCOB: string (nullable = true)\n",
      " |-- CATEND: string (nullable = true)\n",
      " |-- CIDPRI: string (nullable = true)\n",
      " |-- CIDASSOC: string (nullable = true)\n",
      " |-- ORIGEM_PAC: string (nullable = true)\n",
      " |-- DT_INICIO: string (nullable = true)\n",
      " |-- DT_FIM: string (nullable = true)\n",
      " |-- COB_ESF: string (nullable = true)\n",
      " |-- CNES_ESF: string (nullable = true)\n",
      " |-- DESTINOPAC: string (nullable = true)\n",
      " |-- PA_PROC_ID: string (nullable = true)\n",
      " |-- PA_QTDPRO: string (nullable = true)\n",
      " |-- PA_QTDAPR: string (nullable = true)\n",
      " |-- PA_SRV: string (nullable = true)\n",
      " |-- PA_CLASS_S: string (nullable = true)\n",
      " |-- SIT_RUA: string (nullable = true)\n",
      " |-- TP_DROGA: string (nullable = true)\n",
      " |-- LOC_REALIZ: string (nullable = true)\n",
      " |-- INICIO: string (nullable = true)\n",
      " |-- FIM: string (nullable = true)\n",
      " |-- PERMANEN: string (nullable = true)\n",
      " |-- QTDATE: string (nullable = true)\n",
      " |-- QTDPCN: string (nullable = true)\n",
      " |-- NAT_JUR: string (nullable = true)\n",
      "\n",
      "+---------+------+------+------+-----+--------+------+--------------+--------------+----------+--------+---------------+--------+----------+--------+----------+-------+-------+-----+------+-------+---------+------+------+--------+----------+---------+------+-------+--------+----------+----------+---------+---------+------+----------+-------+--------+----------+--------+--------+--------+------+------+-------+\n",
      "|CNES_EXEC|GESTAO|CONDIC| UFMUN|TPUPS|TIPPRE  |MN_IND|       CNPJCPF|       CNPJMNT|DT_PROCESS|DT_ATEND|        CNS_PAC|  DTNASC|TPIDADEPAC|IDADEPAC|NACION_PAC|SEXOPAC|RACACOR|ETNIA|MUNPAC|MOT_COB|DT_MOTCOB|CATEND|CIDPRI|CIDASSOC|ORIGEM_PAC|DT_INICIO|DT_FIM|COB_ESF|CNES_ESF|DESTINOPAC|PA_PROC_ID|PA_QTDPRO|PA_QTDAPR|PA_SRV|PA_CLASS_S|SIT_RUA|TP_DROGA|LOC_REALIZ|  INICIO|     FIM|PERMANEN|QTDATE|QTDPCN|NAT_JUR|\n",
      "+---------+------+------+------+-----+--------+------+--------------+--------------+----------+--------+---------------+--------+----------+--------+----------+-------+-------+-----+------+-------+---------+------+------+--------+----------+---------+------+-------+--------+----------+----------+---------+---------+------+----------+-------+--------+----------+--------+--------+--------+------+------+-------+\n",
      "|  9573313|432110|    PG|432110|   70|      00|     M|88811948000178|88811948000178|    202301|  202301|é{Ç{{äâ~}{üÇ~|19691127|         4|      51|        01|      F|     01| NULL|432110|     28|     NULL|    01|  F323|    F323|        02| 20210121|  NULL|      S| 9573313|        00|0301080208|        1|        1|   115|       002|      N|    NULL|         C|20230101|20230131|      31|     1|     1|   1244|\n",
      "|  9573313|432110|    PG|432110|   70|      00|     M|88811948000178|88811948000178|    202301|  202301|é{Ç{{ü|ü|{~Ç||19760116|         4|      43|        01|      M|     02| NULL|432110|     28|     NULL|    01|  F193|    F193|        02| 20191204|  NULL|      S| 9573313|        00|0301080208|        1|        1|   115|       002|      N|    NULL|         C|20230101|20230131|      31|     1|     1|   1244|\n",
      "|  9573313|432110|    PG|432110|   70|      00|     M|88811948000178|88811948000178|    202301|  202301|é{Ç{{{üä{}~|Çé|19721122|         4|      47|        01|      F|     01| NULL|432110|     28|     NULL|    01|  F109|    F109|        02| 20200310|  NULL|      N|    NULL|        00|0301080208|        1|        1|   115|       002|      N|    NULL|         C|20230101|20230131|      31|     1|     1|   1244|\n",
      "|  9573313|432110|    PG|432110|   70|      00|     M|88811948000178|88811948000178|    202301|  202301|é{Ç{{Ç}ä}~â~~ÇÇ|20040224|         4|      15|        01|      M|     01| NULL|432110|     28|     NULL|    01|  F419|    F419|        02| 20191217|  NULL|      N|    NULL|        00|0301080208|        1|        1|   115|       002|      N|    NULL|         C|20230101|20230131|      31|     1|     1|   1244|\n",
      "|  9573313|432110|    PG|432110|   70|      00|     M|88811948000178|88811948000178|    202301|  202301|é{Ç~{|~Çé}{ä{|19620224|         4|      57|        01|      F|     01| NULL|432110|     28|     NULL|    01|  F200|    F200|        02| 20191008|  NULL|      S| 9573313|        00|0301080208|        1|        1|   115|       002|      N|    NULL|         C|20230101|20230131|      31|     1|     1|   1244|\n",
      "+---------+------+------+------+-----+--------+------+--------------+--------------+----------+--------+---------------+--------+----------+--------+----------+-------+-------+-----+------+-------+---------+------+------+--------+----------+---------+------+-------+--------+----------+----------+---------+---------+------+----------+-------+--------+----------+--------+--------+--------+------+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c5cc004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, trim, upper, when\n",
    "\n",
    "# Exemplo 1: Renomear coluna com espaços e normalizar strings\n",
    "df = df.withColumnRenamed(\"TIPPRE  \", \"TIPPRE\")  # remove espaços do nome da coluna\n",
    "df = df.withColumn(\"CONDIC\", upper(trim(col(\"CONDIC\"))))  # normaliza CONDIC para maiúsculo sem espaços extras\n",
    "\n",
    "# Exemplo 2: Converter tipos de dados\n",
    "df = df.withColumn(\"IDADEPAC\", col(\"IDADEPAC\").cast(IntegerType()))\n",
    "df = df.withColumn(\"PA_QTDPRO\", col(\"PA_QTDPRO\").cast(IntegerType()))\n",
    "df = df.withColumn(\"PA_QTDAPR\", col(\"PA_QTDAPR\").cast(IntegerType()))\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"DTNASC\",                      \n",
    "    to_date(col(\"DTNASC\"), \"yyyyMMdd\") \n",
    ")\n",
    "\n",
    "# Exemplo 3: Filtrar registros inválidos (caso IDADEPAC não seja plausível, por ex: > 120 anos ou < 0)\n",
    "df = df.filter((col(\"IDADEPAC\") >= 0) & (col(\"IDADEPAC\") < 120))\n",
    "\n",
    "# Exemplo 4: Enriquecimento - criar faixa etária\n",
    "df = df.withColumn(\n",
    "    \"FAIXA_ETARIA\",\n",
    "    when(col(\"IDADEPAC\") < 18, \"MENOR\")\n",
    "     .when((col(\"IDADEPAC\") >= 18) & (col(\"IDADEPAC\") < 60), \"MAIOR\")\n",
    "     .when(col(\"IDADEPAC\") >= 60, \"IDOSO\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e027ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "69d1da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de registros a enviar: 82233\n",
      "Exemplo de registro JSON: {\"CNES_EXEC\":\"9573313\",\"GESTAO\":\"432110\",\"CONDIC\":\"PG\",\"UFMUN\":\"432110\",\"TPUPS\":\"70\",\"TIPPRE\":\"00\",\"MN_IND\":\"M\",\"CNPJCPF\":\"88811948000178\",\"CNPJMNT\":\"88811948000178\",\"DT_PROCESS\":\"202301\",\"DT_ATEND\":\"202301\",\"CNS_PAC\":\"é{Ç{{äâ~}{üÇ~\",\"DTNASC\":\"1969-11-27\",\"TPIDADEPAC\":\"4\",\"IDADEPAC\":51,\"NACION_PAC\":\"01\",\"SEXOPAC\":\"F\",\"RACACOR\":\"01\",\"MUNPAC\":\"432110\",\"MOT_COB\":\"28\",\"CATEND\":\"01\",\"CIDPRI\":\"F323\",\"CIDASSOC\":\"F323\",\"ORIGEM_PAC\":\"02\",\"DT_INICIO\":\"20210121\",\"COB_ESF\":\"S\",\"CNES_ESF\":\"9573313\",\"DESTINOPAC\":\"00\",\"PA_PROC_ID\":\"0301080208\",\"PA_QTDPRO\":1,\"PA_QTDAPR\":1,\"PA_SRV\":\"115\",\"PA_CLASS_S\":\"002\",\"SIT_RUA\":\"N\",\"LOC_REALIZ\":\"C\",\"INICIO\":\"20230101\",\"FIM\":\"20230131\",\"PERMANEN\":\"31\",\"QTDATE\":\"1\",\"QTDPCN\":\"1\",\"NAT_JUR\":\"1244\",\"FAIXA_ETARIA\":\"MAIOR\"}\n"
     ]
    }
   ],
   "source": [
    "json_rdd = df.toJSON().collect()\n",
    "\n",
    "print(f\"Total de registros a enviar: {len(json_rdd)}\")\n",
    "print(\"Exemplo de registro JSON:\", json_rdd[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d032830",
   "metadata": {},
   "source": [
    "## Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24e9e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cf7e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura o produtor Kafka (envio de strings, então usaremos encoding de UTF-8)\n",
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'], \n",
    "                         value_serializer=lambda v: v.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12436a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = \"atendimentos_psicossociais\"\n",
    "\n",
    "# Envia cada mensagem JSON para o tópico\n",
    "for record in json_rdd:\n",
    "    producer.send(topic_name, value=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3fa1de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Força envio de qualquer mensagem pendente\n",
    "producer.flush()\n",
    "producer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e96cbadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82233 mensagens enviadas para o tópico 'atendimentos_psicossociais'.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(json_rdd)} mensagens enviadas para o tópico '{topic_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f757b",
   "metadata": {},
   "source": [
    "$kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic andimentos_psicossociais --from-beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3141eed",
   "metadata": {},
   "source": [
    "## Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63b2bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 registros inseridos...\n",
      "2000 registros inseridos...\n",
      "3000 registros inseridos...\n",
      "4000 registros inseridos...\n",
      "5000 registros inseridos...\n",
      "6000 registros inseridos...\n",
      "7000 registros inseridos...\n",
      "8000 registros inseridos...\n",
      "9000 registros inseridos...\n",
      "10000 registros inseridos...\n",
      "11000 registros inseridos...\n",
      "12000 registros inseridos...\n",
      "13000 registros inseridos...\n",
      "14000 registros inseridos...\n",
      "15000 registros inseridos...\n",
      "16000 registros inseridos...\n",
      "17000 registros inseridos...\n",
      "18000 registros inseridos...\n",
      "19000 registros inseridos...\n",
      "20000 registros inseridos...\n",
      "21000 registros inseridos...\n",
      "22000 registros inseridos...\n",
      "23000 registros inseridos...\n",
      "24000 registros inseridos...\n",
      "25000 registros inseridos...\n",
      "26000 registros inseridos...\n",
      "27000 registros inseridos...\n",
      "28000 registros inseridos...\n",
      "29000 registros inseridos...\n",
      "30000 registros inseridos...\n",
      "31000 registros inseridos...\n",
      "32000 registros inseridos...\n",
      "33000 registros inseridos...\n",
      "34000 registros inseridos...\n",
      "35000 registros inseridos...\n",
      "36000 registros inseridos...\n",
      "37000 registros inseridos...\n",
      "38000 registros inseridos...\n",
      "39000 registros inseridos...\n",
      "40000 registros inseridos...\n",
      "41000 registros inseridos...\n",
      "42000 registros inseridos...\n",
      "43000 registros inseridos...\n",
      "44000 registros inseridos...\n",
      "45000 registros inseridos...\n",
      "46000 registros inseridos...\n",
      "47000 registros inseridos...\n",
      "48000 registros inseridos...\n",
      "49000 registros inseridos...\n",
      "50000 registros inseridos...\n",
      "51000 registros inseridos...\n",
      "52000 registros inseridos...\n",
      "53000 registros inseridos...\n",
      "54000 registros inseridos...\n",
      "55000 registros inseridos...\n",
      "56000 registros inseridos...\n",
      "57000 registros inseridos...\n",
      "58000 registros inseridos...\n",
      "59000 registros inseridos...\n",
      "60000 registros inseridos...\n",
      "61000 registros inseridos...\n",
      "62000 registros inseridos...\n",
      "63000 registros inseridos...\n",
      "64000 registros inseridos...\n",
      "65000 registros inseridos...\n",
      "66000 registros inseridos...\n",
      "67000 registros inseridos...\n",
      "68000 registros inseridos...\n",
      "69000 registros inseridos...\n",
      "70000 registros inseridos...\n",
      "71000 registros inseridos...\n",
      "72000 registros inseridos...\n",
      "73000 registros inseridos...\n",
      "74000 registros inseridos...\n",
      "75000 registros inseridos...\n",
      "76000 registros inseridos...\n",
      "77000 registros inseridos...\n",
      "78000 registros inseridos...\n",
      "79000 registros inseridos...\n",
      "80000 registros inseridos...\n",
      "81000 registros inseridos...\n",
      "82000 registros inseridos...\n",
      "83000 registros inseridos...\n",
      "84000 registros inseridos...\n",
      "85000 registros inseridos...\n",
      "86000 registros inseridos...\n",
      "87000 registros inseridos...\n",
      "88000 registros inseridos...\n",
      "89000 registros inseridos...\n",
      "90000 registros inseridos...\n",
      "91000 registros inseridos...\n",
      "92000 registros inseridos...\n",
      "93000 registros inseridos...\n",
      "94000 registros inseridos...\n",
      "95000 registros inseridos...\n",
      "96000 registros inseridos...\n",
      "97000 registros inseridos...\n",
      "98000 registros inseridos...\n",
      "99000 registros inseridos...\n",
      "100000 registros inseridos...\n",
      "101000 registros inseridos...\n",
      "102000 registros inseridos...\n",
      "103000 registros inseridos...\n",
      "104000 registros inseridos...\n",
      "105000 registros inseridos...\n",
      "106000 registros inseridos...\n",
      "107000 registros inseridos...\n",
      "108000 registros inseridos...\n",
      "109000 registros inseridos...\n",
      "110000 registros inseridos...\n",
      "111000 registros inseridos...\n",
      "112000 registros inseridos...\n",
      "113000 registros inseridos...\n",
      "114000 registros inseridos...\n",
      "115000 registros inseridos...\n",
      "116000 registros inseridos...\n",
      "117000 registros inseridos...\n",
      "118000 registros inseridos...\n",
      "119000 registros inseridos...\n",
      "120000 registros inseridos...\n",
      "121000 registros inseridos...\n",
      "122000 registros inseridos...\n",
      "123000 registros inseridos...\n",
      "124000 registros inseridos...\n",
      "125000 registros inseridos...\n",
      "126000 registros inseridos...\n",
      "127000 registros inseridos...\n",
      "128000 registros inseridos...\n",
      "129000 registros inseridos...\n",
      "130000 registros inseridos...\n",
      "131000 registros inseridos...\n",
      "132000 registros inseridos...\n",
      "133000 registros inseridos...\n",
      "134000 registros inseridos...\n",
      "135000 registros inseridos...\n",
      "136000 registros inseridos...\n",
      "137000 registros inseridos...\n",
      "138000 registros inseridos...\n",
      "139000 registros inseridos...\n",
      "140000 registros inseridos...\n",
      "141000 registros inseridos...\n",
      "142000 registros inseridos...\n",
      "143000 registros inseridos...\n",
      "144000 registros inseridos...\n",
      "145000 registros inseridos...\n",
      "146000 registros inseridos...\n",
      "147000 registros inseridos...\n",
      "148000 registros inseridos...\n",
      "149000 registros inseridos...\n",
      "150000 registros inseridos...\n",
      "151000 registros inseridos...\n",
      "152000 registros inseridos...\n",
      "153000 registros inseridos...\n",
      "154000 registros inseridos...\n",
      "155000 registros inseridos...\n",
      "156000 registros inseridos...\n",
      "157000 registros inseridos...\n",
      "158000 registros inseridos...\n",
      "159000 registros inseridos...\n",
      "160000 registros inseridos...\n",
      "161000 registros inseridos...\n",
      "162000 registros inseridos...\n",
      "163000 registros inseridos...\n",
      "164000 registros inseridos...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Consome as mensagens do tópico e insere no MongoDB\u001b[39;00m\n\u001b[1;32m     23\u001b[0m count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m consumer:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# msg.value já é uma string JSON decodificada\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     registro_json \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue  \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# converter string JSON para dicionário Python\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pyspark-etl/lib/python3.10/site-packages/kafka/consumer/group.py:1188\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_generator_v2()\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pyspark-etl/lib/python3.10/site-packages/kafka/consumer/group.py:1160\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1159\u001b[0m     timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumer_timeout \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[0;32m-> 1160\u001b[0m     record_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39miteritems(record_map):\n\u001b[1;32m   1162\u001b[0m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[1;32m   1166\u001b[0m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/pyspark-etl/lib/python3.10/site-packages/kafka/consumer/group.py:693\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    691\u001b[0m inner_timeout_ms \u001b[38;5;241m=\u001b[39m timeout_ms_fn(timeout_ms, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[0;32m--> 693\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_timeout_ms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "File \u001b[0;32m~/.virtualenvs/pyspark-etl/lib/python3.10/site-packages/kafka/consumer/group.py:736\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m records\n\u001b[0;32m--> 736\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_timeout_ms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_to_next_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
      "File \u001b[0;32m~/.virtualenvs/pyspark-etl/lib/python3.10/site-packages/kafka/client_async.py:684\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[0;34m(self, timeout_ms, future)\u001b[0m\n\u001b[1;32m    677\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m    678\u001b[0m             user_timeout_ms,\n\u001b[1;32m    679\u001b[0m             metadata_timeout_ms,\n\u001b[1;32m    680\u001b[0m             idle_connection_timeout_ms,\n\u001b[1;32m    681\u001b[0m             request_timeout_ms)\n\u001b[1;32m    682\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[1;32m    688\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[0;32m~/.virtualenvs/pyspark-etl/lib/python3.10/site-packages/kafka/client_async.py:727\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[1;32m    726\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 727\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:469\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "\n",
    "topic_name = \"atendimentos_psicossociais\"\n",
    "\n",
    "# Conectar ao MongoDB (banco de dados 'siasus', coleção 'atendimentos')\n",
    "mongo_client = MongoClient(\"localhost\", 27017)\n",
    "db = mongo_client[\"siasus\"]\n",
    "collection = db[\"atendimentos\"]\n",
    "\n",
    "# Configurar o consumidor Kafka\n",
    "consumer = KafkaConsumer(\n",
    "    topic_name,\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    auto_offset_reset='earliest',  # garante começar do início do tópico\n",
    "    enable_auto_commit=True,\n",
    "    group_id=\"grupo-siasus-1\",\n",
    "    value_deserializer=lambda v: v.decode('utf-8')\n",
    ")\n",
    "\n",
    "# Consome as mensagens do tópico e insere no MongoDB\n",
    "count = 0\n",
    "for msg in consumer:\n",
    "    # msg.value já é uma string JSON decodificada\n",
    "    registro_json = msg.value  \n",
    "    # converter string JSON para dicionário Python\n",
    "    registro = json.loads(registro_json)\n",
    "    # inserir no Mongo\n",
    "    collection.insert_one(registro)\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(f\"{count} registros inseridos...\")\n",
    "\n",
    "print(f\"Consumo finalizado. Total de registros inseridos: {count}\")\n",
    "mongo_client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6d4a0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164466\n",
      "{'_id': ObjectId('680aef97c48ba2998f1e4216'), 'CNES_EXEC': '9573313', 'GESTAO': '432110', 'CONDIC': 'PG', 'UFMUN': '432110', 'TPUPS': '70', 'TIPPRE': '00', 'MN_IND': 'M', 'CNPJCPF': '88811948000178', 'CNPJMNT': '88811948000178', 'DT_PROCESS': '202301', 'DT_ATEND': '202301', 'CNS_PAC': 'é{Ç{{äâ\\x7f\\x7f~}{üÇ~', 'DTNASC': '1969-11-27', 'TPIDADEPAC': '4', 'IDADEPAC': 51, 'NACION_PAC': '01', 'SEXOPAC': 'F', 'RACACOR': '01', 'MUNPAC': '432110', 'MOT_COB': '28', 'CATEND': '01', 'CIDPRI': 'F323', 'CIDASSOC': 'F323', 'ORIGEM_PAC': '02', 'DT_INICIO': '20210121', 'COB_ESF': 'S', 'CNES_ESF': '9573313', 'DESTINOPAC': '00', 'PA_PROC_ID': '0301080208', 'PA_QTDPRO': 1, 'PA_QTDAPR': 1, 'PA_SRV': '115', 'PA_CLASS_S': '002', 'SIT_RUA': 'N', 'LOC_REALIZ': 'C', 'INICIO': '20230101', 'FIM': '20230131', 'PERMANEN': '31', 'QTDATE': '1', 'QTDPCN': '1', 'NAT_JUR': '1244', 'FAIXA_ETARIA': 'MAIOR'}\n"
     ]
    }
   ],
   "source": [
    "print(collection.count_documents({}))\n",
    "# ou, para ver um exemplo de documento:\n",
    "doc = collection.find_one()\n",
    "print(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
